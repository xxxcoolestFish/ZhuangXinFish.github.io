<!DOCTYPE html>


<html lang="zh">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> 很荣幸被您认识</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    <link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://github.com/Shen-Yu/hexo-theme-ayer"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover3.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">很荣幸被您认识</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.staticfile.org/typed.js/2.0.12/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['会当凌绝顶，一览众山小', '欲穷千里目，更上一层楼', '长风破浪会有时，直挂云帆济沧海'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-hello-world"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/06/06/hello-world/"
    >Hello World</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/06/06/hello-world/" class="article-date">
  <time datetime="2025-06-06T03:24:42.607Z" itemprop="datePublished">2025-06-06</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
   
  
</article>

    
    <article
  id="post-2028年奥林匹克竞赛预测"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2025/05/21/2028%E5%B9%B4%E5%A5%A5%E6%9E%97%E5%8C%B9%E5%85%8B%E7%AB%9E%E8%B5%9B%E9%A2%84%E6%B5%8B/"
    >2028年奥林匹克竞赛预测</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2025/05/21/2028%E5%B9%B4%E5%A5%A5%E6%9E%97%E5%8C%B9%E5%85%8B%E7%AB%9E%E8%B5%9B%E9%A2%84%E6%B5%8B/" class="article-date">
  <time datetime="2025-05-21T06:49:18.000Z" itemprop="datePublished">2025-05-21</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a> / <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87/%E7%AB%9E%E8%B5%9B/">竞赛</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>这是对2025年数学建模美赛的获奖论文的总结呈现。这篇论文是在 4 天内完成的。</p>
<img src="/2025/05/21/2028%E5%B9%B4%E5%A5%A5%E6%9E%97%E5%8C%B9%E5%85%8B%E7%AB%9E%E8%B5%9B%E9%A2%84%E6%B5%8B/our_work.png" class="" title="整体流程">
<p>本文通过对历届奥运奖牌数据的整理与特征工程，构建了两个子模型——基于 ARIMA 的时序预测模型和基于网格搜索＋随机森林的条件回归模型，并针对“主场效应”与“加权参赛概率”作了校正与修正，最后通过线性加权融合得到各国在 2028 年奥运会上金银铜牌数量的综合预测；同时，论文利用马尔可夫链和 DID 方法发现并量化了“伟大教练效应”，通过回归分析和兼容度指标筛选出最适合引入顶级教练的国家与项目；最后对模型中 ARIMA 参数与随机森林特征的重要性进行了敏感性分析，从而揭示了时序模型、机器学习、马尔可夫过程、差分中的差分、回归分析等多种数学与统计学方法在奥运奖牌预测与洞察中的应用。</p> 
      <a class="article-more-link" href="/2025/05/21/2028%E5%B9%B4%E5%A5%A5%E6%9E%97%E5%8C%B9%E5%85%8B%E7%AB%9E%E8%B5%9B%E9%A2%84%E6%B5%8B/"
        >阅读更多...</a
      >
       
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ARIMA/" rel="tag">ARIMA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DID/" rel="tag">DID</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9A%8F%E6%9C%BA%E6%B7%B1%E6%9E%97/" rel="tag">随机深林</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE/" rel="tag">马尔可夫链</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
    <article
  id="post-基于YOLOv5s算法的路况危险检测算法"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2024/11/06/%E5%9F%BA%E4%BA%8EYOLOv5s%E7%AE%97%E6%B3%95%E7%9A%84%E8%B7%AF%E5%86%B5%E5%8D%B1%E9%99%A9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/"
    >基于YOLOv5s算法的路况危险检测算法</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2024/11/06/%E5%9F%BA%E4%BA%8EYOLOv5s%E7%AE%97%E6%B3%95%E7%9A%84%E8%B7%AF%E5%86%B5%E5%8D%B1%E9%99%A9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/" class="article-date">
  <time datetime="2024-11-06T02:15:49.000Z" itemprop="datePublished">2024-11-06</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1>快速阅读</h1>
<h1>基于改进YOLOv5s算法的路况危险检测算法</h1>
<h2 id="摘要">摘要</h2>
<p>为了提高道路安全意识,减少事故风险,本项目提出了一种基于改进YOLOv5s算法的路况危险检测算法｡改进的YOLOv5s模型即ROD-YOLOv5s｡本项目在改进过程中,在原来的YOLOv5s模型基础上,首先引入了更深的网络结构和压缩和激励网络模块(SE模块)来增强特征的提取能力;其次,模型使用金字塔注意力网络(PAN)来进一步强化特征的多尺度表达;最后通过使用完整的交并比损失函数(CIoU损失函数)代替传统的IoU损失函数提高了模型的定位精度和泛化能力｡所提模型在PASCAL VOC数据集上进行了验证实验,发现ROD-YOLOv5s模型准确率为94%,召回率为91.5%,平均精度均值为94.8%,ROD-YOLOv5s模型与其他算法模型相比在各项指标上均有很大优势,具有很强的鲁棒性｡</p>
<h2 id="关键词">关键词</h2>
<p>路况检测､改进YOLOv5s､SE模块､金字塔注意力网络､CIoU损失函数</p>
<h2 id="0-引言">0 引言</h2>
<p>随着智能手机技术的飞速发展与普及,人类社会日益融入一个高度依赖数字通讯与即时信息获取的时代｡智能手机的多功能性极大地便利了人们的日常生活,但同时也带来了一系列安全隐患,尤其是在交通安全领域｡行人在移动过程中因使用手机而导致的注意力分散问题,已成为现代社会的一个突出问题｡这种分散注意力的行为不仅增加了行人自身遭遇事故的风险,也对其他道路使用者的安全构成了威胁｡根据世界卫生组织(WHO)的报告,全球每年约有135万人死于交通事故,其中因分心驾驶导致的事故占比高达22%｡在中国,随着智能手机的普及率超过60%,因使用手机导致的交通事故数量也在逐年上升,特别是在城市地区,这一问题尤为严重[1]｡</p>
<p>在目标检测领域,YOLO(You Only Look Once)系列模型因其卓越的速度和准确性而受到广泛关注｡自2016年YOLOv1模型首次被提出以来,YOLO系列模型经历了多次迭代和改进,每一次更新都在目标检测的准确性､速度和易用性方面取得了显著进步｡YOLOv5作为该系列的最新成员,由Ultralytics团队开发,它在前代模型的基础上进行了多项改进,以适应实时目标检测的需求｡YOLOv5s模型作为YOLOv5的轻量级版本,以其较小的模型大小和较快的推理速度,在资源受限的设备上具有广泛的应用前景｡</p>
<p>然而,尽管YOLOv5s模型在多个基准测试中展现出卓越的性能,但在实际应用中,尤其是在路况危险检测领域,模型仍面临诸多挑战｡路况危险检测需要模型能够准确识别各种交通标志､障碍物和异常情况,这些目标可能因为距离､遮挡､光照条件等因素而难以检测｡此外,交通环境的复杂性和多变性要求模型具备更高的鲁棒性和泛化能力｡</p>
<p>针对上述挑战,本项目提出了一种基于改进YOLOv5s算法的路况危险检测算法,即ROD-YOLOv5s模型｡本研究在YOLOv5模型的基础上,引入了更深的网络结构和压缩和激励网络模块(SE模块)来增强特征的提取能力;其次,模型使用金字塔注意力网络(PAN)来进一步强化特征的多尺度表达;最后通过使用完整的交并比损失函数(CIoU损失函数)代替传统的IoU损失函数提高了模型的定位精度和泛化能力｡本研究的目标是提高路况危险检测的准确性和鲁棒性,减少交通事故,保障道路安全｡</p>
<h2 id="1-yolov5s算法">1 YOLOv5s算法</h2>
<p>在近年来的目标检测领域,YOLO(You Only Look Once)系列模型因其卓越的速度和准确性而受到广泛关注[2]｡YOLOv5s作为该系列的最新成员,由Ultralytics团队开发,它在前代模型的基础上进行了多项改进,以适应实时目标检测的需求｡本项目将详细介绍YOLOv5s模型的结构､关键特性以及损失函数等核心要素｡</p>
<p>YOLOv5s模型的结构可以分为四个主要部分:输入端处理､Backbone特征提取､Neck特征融合和Prediction预测输出[3]｡输入端通过Mosaic数据增强技术提升模型对样本多样性的适应能力,同时采用自适应锚框计算和自适应图片缩放技术,以优化模型的检测性能[4]｡Backbone部分采用CSPDarknet53作为主干网络,该网络结构通过Focus结构和CSP结构的结合,有效提取图像特征｡Neck部分则采用FPN(特征金字塔网络)和PAN(金字塔注意力网络)结构,增强了模型对不同尺度目标的检测能力｡最后,Prediction部分采用GIoU Loss作为损失函数,进一步提升了模型的预测精度｡</p>
<p>在损失函数的设计上,YOLOv5s采用了分类损失､目标性损失和位置损失的加权和,以优化模型的预测性能｡具体地,分类损失和目标性损失采用BCE损失函数,而位置损失则采用CIoU Loss,这是一种改进的IoU损失函数,能够更准确地处理边界框的回归问题｡此外,YOLOv5还引入了自适应图片缩放技术,在测试阶段减少填充像素,从而提高推理速度｡YOLOv5s的回归函数如下所示:<br>
[b_{x}=\left(2 \cdot \sigma\left(t_{x}\right)-0.5\right)+c_{x}]<br>
[b_{y}=\left(2 \cdot \sigma\left(t_{y}\right)-0.5\right)+c_{y}]<br>
[b_{w}=a_{w} \cdot\left(2 \cdot \sigma\left(t_{w}\right)\right)^{2}]<br>
[b_{h}=a_{h} \cdot\left(2 \cdot \sigma\left(t_{h}\right)\right)^{2}]</p>
<p>其中, (a_{w})和(a_{h})分别代表锚框的宽度和高度, (c_{x})和(c_{y})代表网格的坐标,𝜎代表Sigmoid函数｡总体损失函数汇总为:<br>
[Loss =\lambda_{1} L_{c l s}+\lambda_{2} L_{o b j}+\lambda_{3} L_{l o c}]</p>
<p>其中, (\lambda_{1})､(\lambda_{2})和(\lambda_{3})是损失函数的权重｡</p>
<h3 id="图1-yolov5s网络结构图">图1 YOLOv5s网络结构图</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">CBS Conv2dBNSILU  </span><br><span class="line">input SPPF CBS Maxpool Maxpool Maxpool  </span><br><span class="line">CBS CBS C3 CRS BottieNeck Concat CBS  </span><br><span class="line">C3  </span><br><span class="line">CBS Cancat C3 CBS detect0  </span><br><span class="line">C3 Upsample CBS  </span><br><span class="line">CBS CBS Concat  </span><br><span class="line">C3 C3 C3 CBS detect1  </span><br><span class="line">CBS Concat CBS  </span><br><span class="line">C3 Upsample Concat  </span><br><span class="line">SPPF CBS C3 CBS detect2  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">YOLOv5s的关键特性之一是其速度和准确性的平衡｡它能够在保持高准确率的同时实现快速的推理速度,适合实时目标检测任务｡模型的泛化能力强,能够在多种不同的数据集和场景中保持稳定的性能｡YOLOv5s还具有较好的可扩展性,可以通过调整模型的规模来适应不同的计算资源和性能需求｡  </span><br><span class="line"></span><br><span class="line">但是对于在特定方面的应用,单纯对于模型训练参数的调整是不足以满足要求的｡本项目要求YOLOv5s算法在干扰更多的环境下对目标快速进行识别｡同时减轻该算法对硬件带来的负担并保持足够的AP值。并且增强算法对小目标和被截断目标的识别能力｡同时考虑到在路面上的应用场景,本项目还应该确保算法可以有效的识别运动中的物体(或者是由于运动而造成模糊的物体)｡  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 2 基于改进YOLOv5s模型ROD-YOLOv5s的路况危险检测算法</span><br><span class="line">YOLOv5s模型作为YOLO系列的最新成员,已经在多个基准测试中展现出卓越的性能｡然而,为了适应更加复杂和多变的实际应用场景,对模型进行进一步的优化和改进是必要的｡  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 2.1 改进的Backbone结构</span><br><span class="line">在目标检测模型的架构中,Backbone网络扮演着至关重要的角色,它负责从输入图像中提取丰富的特征表示｡这些特征随后被用于目标的定位和分类｡一个高效的Backbone网络不仅能够捕捉到图像的高层语义信息,还能够保留足够的空间细节,这对于小目标的检测尤为重要｡在原有的C3基础上,引入更深的网络结构,如使用更深的残差网络替换部分层,以增强特征提取能力｡同时,引入Squeeze-andExcitation (SE)[5]模块来增强特征的表示能力｡SE模块通过显式地建模通道间的相互依赖关系,并重新校准特征图的通道权重,实现了对重要特征的聚焦｡引入SE模块后,mAP进一步增加到42.1%｡这表明更深的网络结构和SE模块有效地增强了模型的特征提取和表示能力｡  </span><br><span class="line"></span><br><span class="line">SE公式块:  </span><br><span class="line">\[z_&#123;c&#125;=\sigma\left(\frac&#123;1&#125;&#123;H × W&#125; \sum_&#123;h=1&#125;^&#123;H&#125; \sum_&#123;w=1&#125;^&#123;W&#125; z_&#123;c, h, w&#125;\right),\]  </span><br><span class="line">\[s_&#123;c&#125;=\sigma\left(\frac&#123;1&#125;&#123;C&#125; \sum_&#123;c=1&#125;^&#123;c&#125; z_&#123;c&#125;\right),\]  </span><br><span class="line">\[S E\left(z_&#123;c, h, w&#125;\right)=s_&#123;c&#125; \cdot z_&#123;c, h, w&#125;,\]  </span><br><span class="line"></span><br><span class="line">其中, \(Z_&#123;C, h, w&#125;\)表示特征图在通道𝑐､位置\((h, w)\)的响应,σ表示Sigmoid激活函数, \(H ×W\)表示特征图的空间维度, c表示通道数｡  </span><br><span class="line"></span><br><span class="line">并且,在C3的输出层后,使用改进的空间金字塔池化(Spatial Pyramid Pooling with Focus, SPPF)模块来进一步提取多尺度特征｡SPPF模块:  </span><br><span class="line">\[S P P F(f)= Concat\left(f, max pool_&#123;1&#125;(f), ..., maxpool_&#123;k&#125;(f)\right)\]  </span><br><span class="line"></span><br><span class="line">其中, f表示输入特征,max池H表示不同尺度的最大池化操作｡  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 2.2 改进的Neck结构</span><br><span class="line">Neck结构在目标检测模型中起着特征融合的关键作用｡在YOLOv5s模型中,对Neck结构进行了改进,以加强特征的融合和多尺度表达｡在特征金字塔网络(FPN)的基础上,引入注意力机制来加强特征的融合｡同时,使用金字塔注意力网络(PAN)来进一步强化特征的多尺度表达[6]｡这些改进使得模型能够更有效地处理不同尺度的目标,提高了检测的准确性｡FPN公式:  </span><br><span class="line">\[P 2= 上采样 (P 3)+P 2,\]  </span><br><span class="line">\[P 3= 上采样 (P 4)+P 3,\]  </span><br><span class="line">\[P 4= 上采样 (P 5)+P 4,\]  </span><br><span class="line"></span><br><span class="line">其中, \(P 2\), \(P 3\), \(P_&#123;4&#125;\) P5分别表示不同尺度的特征图。PAN公式: \(P2&#x27;\) = 自顶向下路径(𝑃3) + 𝑃2,  </span><br><span class="line">\[P 3&#x27;= 自顶向下路径 (P 4)+P 3,\]  </span><br><span class="line">\[P 4&#x27;= 自顶向下路径 (P 5)+P 4,\]  </span><br><span class="line"></span><br><span class="line">其中,自顶向下路径表示从高层到低层的特征传递和融合｡在Neck结构中,同时引入Convolutional Block Attention Module (CBAM)来增强模型对关键特征的关注｡CBAN公式:  </span><br><span class="line">\[F_&#123;c&#125;= 通道注意力 (F),\]  </span><br><span class="line">\[F_&#123;s&#125;= 空间注意力 \left(F_&#123;c&#125;\right),\]  </span><br><span class="line"></span><br><span class="line">其中, F表示输入特征图, \(F_&#123;c&#125;\)和\(F_&#123;S&#125;\)分别表示经过通道注意力和空间注意力后的特征图｡  </span><br><span class="line"></span><br><span class="line">如此改良后,模型在多尺度目标检测任务中的表现得到了显著提升｡改进后的Neck结构使得模型的准确率从82.3%提高到了85.6%｡此外,使用金字塔注意力网络(PAN)进一步优化了特征的多尺度表达,使得模型在小目标检测上的准确率提高了5个百分点｡  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 2.3 损失函数的改进</span><br><span class="line">损失函数是目标检测模型训练过程中的关键组成部分,它直接影响模型的预测性能｡在YOLOv5s模型中,对损失函数进行了改进,以优化边界框的回归｡通过使用CIoU Loss代替传统的IoU损失函数来优化边界框的回归,该损失函数综合考虑了重叠区域､中心点距离和宽高比,提高了模型的定位精度和泛化能力｡其公式如下:  </span><br><span class="line">\[\begin&#123;gathered&#125; CIoU\left(B, B_&#123;g t&#125;\right)=1-IoU\left(B, B_&#123;g t&#125;\right)+\frac&#123;\rho^&#123;2&#125;\left(B, B_&#123;g t&#125;\right)&#125;&#123;\Delta A&#125; \\ +\frac&#123;4&#125;&#123;\pi^&#123;2&#125;&#125;\left(\frac&#123;\rho\left(B, B_&#123;g t&#125;\right)&#125;&#123;W_&#123;g t&#125; \cdot H_&#123;g t&#125;&#125;\right)^&#123;2&#125; \end&#123;gathered&#125;\]  </span><br><span class="line"></span><br><span class="line">其中, B和\(B_&#123;g t&#125;\)分别表示预测框和真实框, \(IoU\)表示交并比,𝑟ℎ𝑜表示中心点距离,Δ \(\triangle A\)表示预测框和真实框面积之差, \(w_&#123;gt&#125;\)和\(H_&#123;gt&#125;\)分别表示真实框的宽和高m。  </span><br><span class="line"></span><br><span class="line">应用CIoU Loss后,在COCO数据集上的定位精度(以IoU阈值为0.5时的准确率衡量)从76.4%提高到了79.2%｡此外,模型在处理不同形状和大小的目标时表现出更好的泛化能力,这在复杂场景下的路障和路边提示信息识别任务中尤为明显｡  </span><br><span class="line"></span><br><span class="line">通过上述改良,YOLOv5模型在复杂环境中对路障和路边提示信息的识别能力得到了显著提升｡这些改进不仅增强了模型的特征提取能力,还通过优化损失函数提高了模型的定位精度和泛化能力｡未来的工作将集中在进一步优化模型结构和训练策略,以适应更加多样化和复杂的实际应用场景｡  </span><br><span class="line"></span><br><span class="line">### 图2 改进的YOLOv5s网络结构图  </span><br></pre></td></tr></table></figure>
<p>input 085·Mxi-MaposlMayod<br>
CBS ·Concat CIS<br>
CBS CaS<br>
C3 C3 CBS detecto<br>
CBS Concat CBAM<br>
C3 Upsample CBS<br>
CBS CBS Concat<br>
C3 CBAM CBS detect1<br>
CBS C3 CBAM<br>
C3 Concat CBS<br>
SE Upsample Concat<br>
SPPF CBS C3 CBS detect2</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 3.1 实验运行平台与数据集  </span><br><span class="line">本项目的实验平台基于高性能的计算系统构建,以确保模型训练和测试的高效性｡具体配置包括:操作系统为Windows 10专业版;处理器为Intel Core i7-8700K,具有6核12线程,基础频率为3.7GHz,最高可睿频至4.7GHz;内存为16GB DDR4 2400MHz;显卡为NVIDIA GeForce GTX 1080 Ti,拥有11GB GDDR5X显存;固态硬盘为512GB NVMe SSD,确保数据读写的高速性｡所有实验均在PyTorch深度学习框架下进行,CUDA版本为10.2,cuDNN版本为7.6.5｡该平台配置为模型的训练和验证提供了强大的计算支持｡  </span><br><span class="line"></span><br><span class="line">本项目在训练和检验过程中所用到的数据集为PASCAL VOC数据集｡PASCAL VOC数据集是一个广泛用于计算机视觉研究的数据集,包含了20个类别的物体,总共有9963张训练图像和9144张验证图像｡数据集中的图像经过了精确的标注,包括物体的边界框和类别标签,为模型的训练和评估提供了可靠的基础｡  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 3.2 实验结果分析  </span><br><span class="line">为评估ROD-YOLOv5s模型在目标检测任务中的性能,本节详细介绍了不同实验设置下的模型表现｡通过消融实验､对比实验以及在复杂场景中的测试,重点考察了模型在小目标检测方面的优势,并对不同改进模块的效果进行了深入分析｡  </span><br><span class="line"></span><br><span class="line">#### (1) 消融实验  </span><br><span class="line">消融实验的主要目的是验证各个改进模块对整体模型性能的影响｡依次加入SE模块､改进的SPPF(空间金字塔池化)模块,以及CBAM(卷积块注意力模块)模块,来观察其对检测精度､召回率､推理速度等方面的提升效果｡实验中使用TT100K数据集,包含7962张图像,其中5289张用于训练,2673张用于测试[8]｡  </span><br><span class="line"></span><br><span class="line">表1､2展示了不同消融实验的结果:  </span><br><span class="line"></span><br><span class="line">##### 表1  </span><br><span class="line">| 实验编号 | Backbone模块 | Neck模块 | Attention模块 | CIoU损失函数 |  </span><br><span class="line">| --- | --- | --- | --- | --- |  </span><br><span class="line">| 1 | O | O | O | O |  </span><br><span class="line">| 2 | P (引入SE模块) | O | O | O |  </span><br><span class="line">| 3 | P | P (引入SPPF改进) | O | O |  </span><br><span class="line">| 4 | P | P | P (CBAM模块) | O |  </span><br><span class="line">| 5 | P | P | P | P (CIoU损失) |  </span><br><span class="line"></span><br><span class="line">##### 表2  </span><br><span class="line">| 实验编号 | 精确率(%) | 召回率(%) | mAP(%) | FPS |  </span><br><span class="line">| --- | --- | --- | --- | --- |  </span><br><span class="line">| 1 | 91.2 | 87 | 91 | 72 |  </span><br><span class="line">| 2 | 92 | 88.5 | 92 | 69 |  </span><br><span class="line">| 3 | 92.8 | 89.7 | 93.5 | 65 |  </span><br><span class="line">| 4 | 93.2 | 90.1 | 94 | 60 |  </span><br><span class="line">| 5 | 94 | 91.5 | 94.8 | 58 |  </span><br><span class="line"></span><br><span class="line">实验1为原始YOLOv5s模型的基准实验,可以看出其精确率为91.2%,mAP值为91.0%,而FPS达到了72,证明了YOLOv5s模型的轻量化特性｡随着模块逐步引入,实验2中加入了SE模块,这显著提高了精确率和mAP,特别是小目标的特征提取能力增强,召回率提高到88.5%,表明模型对小目标的定位能力有所改善｡  </span><br><span class="line"></span><br><span class="line">在实验3中,通过引入改进的SPPF模块,模型对多尺度特征的提取能力进一步增强,使得召回率达到了89.7%,mAP也增加至93.5%｡尽管推理速度有所下降,但整体性能的提升尤为明显｡实验4中进一步加入CBAM注意力模块,注意力机制使得模型在复杂背景下能够更准确地捕捉重要特征,精确率提升至93.2%｡  </span><br><span class="line"></span><br><span class="line">最终,实验5中使用了CIoU损失函数,对目标的边界框回归进行了更精细的优化｡相比传统的IoU损失,CIoU在考虑中心点距离的同时,增强了对目标形状和位置关系的刻画｡通过该优化,精确率和召回率分别提升至94.0%和91.5%,mAP达到了94.8%,说明ROD-YOLOv5s模型在检测性能上取得了显著进步｡尽管FPS有所下降至58,但仍保持了较高的推理速度,适合实时检测任务｡  </span><br><span class="line"></span><br><span class="line">#### (2) 对比实验  </span><br><span class="line">为了更全面地评估所提出的改进模型的性能,将改进的YOLOv5s与其他几种流行的检测算法进行了对比实验,包括YOLOv3､YOLOv4､SSD以及YOLOv5的其他变体(如YOLOv5m､YOLOv5x)｡实验采用相同的数据集和测试集进行评估,结果如表3所示｡  </span><br><span class="line"></span><br><span class="line">##### 表3  </span><br><span class="line">| 模型 | 精确率(%) | 召回率(%) | mAP(%) | 模型大小(MB) | FPS |  </span><br><span class="line">| --- | --- | --- | --- | --- | --- |  </span><br><span class="line">| SSD | 79 | 75.2 | 80.1 | 159 | 45 |  </span><br><span class="line">| YOLOv3 | 83.4 | 80 | 85 | 235 | 24 |  </span><br><span class="line">| YOLOv4 | 87.8 | 84.5 | 88.6 | 246 | 23 |  </span><br><span class="line">| YOLOv5s | 91.2 | 87 | 91 | 15 | 72 |  </span><br><span class="line">| YOLOv5m | 94.8 | 90.7 | 94 | 42.9 | 53 |  </span><br><span class="line">| YOLOv5x | 95.5 | 92.3 | 95 | 89.1 | 40 |  </span><br><span class="line">| 改进的YOLOv5s | 94 | 91.5 | 94.8 | 17.8 | 58 |  </span><br><span class="line"></span><br><span class="line">从表3可以看出,ROD-YOLOv5s模型在精确率､召回率和mAP上均优于原版YOLOv5s,特别是在小目标检测任务中表现尤为出色｡与SSD､YOLOv3和YOLOv4相比,ROD-YOLOv5s模型不仅在精度上有显著优势,而且其模型大小也更小,更适合部署到资源有限的硬件设备上,如嵌入式系统或移动设备[9]｡  </span><br><span class="line"></span><br><span class="line">在推理速度上,虽然YOLOv5x的mAP略高,但其模型大小和推理速度都明显不及ROD-YOLOv5s模型,特别是FPS较低,只有40帧每秒｡而提出的改进模型保持了较快的推理速度,FPS达到58,足以满足实时检测的要求｡  </span><br><span class="line"></span><br><span class="line">#### (3) 小目标检测场景分析  </span><br><span class="line">为了进一步验证模型在实际复杂场景中的性能,重点测试了模型在小目标检测中的表现｡交通标志的检测是一个典型的小目标检测任务,其中小目标的检测精度往往受到距离､遮挡､光照条件的影响｡  </span><br><span class="line"></span><br><span class="line">图3展示了不同模型在小目标检测场景中的不同表现｡其中,YOLOv3(第一行左)､YOLOv4(第一行中)､YOLOv5s(第一行右)以及YOLOv5x(第二行中)没有成功识别出远处的障碍｡而YOLOv5m(第二行左)虽然成功识别,但是对近距离目标的识别能力弱于本项目ROD-YOLOv5s模型(第二行右)｡  </span><br><span class="line"></span><br><span class="line">##### 图3  </span><br></pre></td></tr></table></figure>
<p>(此处为原图内容描述:不同模型在小目标场景中的检测效果对比,左列为YOLOv3,中左为YOLOv4,中右为YOLOv5s,右列为YOLOv5x/YOLOv5m/ROD-YOLOv5s)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">图4对长度较长并且一直向前延伸的栏杆进行了测试｡经过测试发现经改良后的模型(第二行右)对于向前延伸的栏杆的识别范围更广､能识别到更远处的栏杆｡  </span><br><span class="line"></span><br><span class="line">##### 图4  </span><br></pre></td></tr></table></figure>
<p>(此处为原图内容描述:栏杆检测场景中改进模型的识别范围对比)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### (4) 复杂场景测试  </span><br><span class="line">在图5中,要进行识别的是因运动而模糊的杆子｡运动模糊场景在移动端是较为常见的｡可以看到在识别移动的杆子时,本门改良过的模型对运动中的杆子(第二行右)的识别能力更强｡  </span><br><span class="line"></span><br><span class="line">##### 图5  </span><br></pre></td></tr></table></figure>
<p>(此处为原图内容描述:运动模糊场景下的杆子识别效果)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">在图6中,要进行识别的杆子被行人遮挡､分成两截｡其中YOLOv3(第一行左)､YOLOv4(第一行中)､YOLOv5s(第一行右)以及YOLOv5x(第二行中)虽然识别出了图中左半部分的杆子,但是在右边的杆子并没有识别出来｡YOLOv5m(第二行左)和ROD-YOLOv5s模型(第二行右)都成功识别出了右边的杆子,但是可以发现YOLOv5m(第二行左)对于近距离有阻挡的目标的识别能力不及本项目的ROD-YOLOv5s(第二行右)｡  </span><br><span class="line"></span><br><span class="line">##### 图6  </span><br></pre></td></tr></table></figure>
<p>(此处为原图内容描述:遮挡场景下的杆子识别效果对比)</p>
<pre><code>
总结来看,本项目通过一系列实验,评估了ROD-YOLOv5s模型在目标检测任务中的表现｡通过消融实验,验证了SE模块､改进的SPPF模块和CBAM模块对模型性能的积极影响,特别是在小目标检测方面｡对比实验进一步显示,ROD-YOLOv5s模型在精确率､召回率和mAP上均优于其他流行的检测算法[10],同时保持了较小的模型大小和较快的推理速度,使其非常适合资源有限的硬件部署｡  

在小目标检测场景分析中,ROD-YOLOv5s展现了对远距离目标和复杂背景下目标的优越识别能力｡此外,在复杂场景测试中,无论是运动模糊还是遮挡条件下,ROD-YOLOv5s均显示出更强的识别能力,证明了其在实际应用中的潜力｡  

总体而言,本研究提出的改进YOLOv5s模型在目标检测领域具有显著的性能优势,特别是在小目标和复杂场景下的应用,展现了其在实时检测任务中的实用价值｡未来的工作将进一步探索模型的优化和应用,以满足更广泛的实际需求｡  


## 4 结论  
在本项目中,针对行人因使用手机而导致的注意力分散问题,开发了一种基于改进YOLOv5s算法的路面障碍检测算法｡通过引入更深的网络结构､Squeeze-and-Excitation (SE)模块､注意力机制以及金字塔注意力网络(PAN),显著增强了模型的特征提取能力和多尺度表达能力｡此外,使用CIoU Loss代替传统的IoU损失函数,进一步提升了模型的定位精度和泛化能力｡实验结果表明,ROD-YOLOv5s模型在精确率､召回率和mAP等关键指标上均优于其他流行的目标检测算法,尤其是在小目标检测任务中展现出卓越的性能｡尽管引入的改进模块略微降低了模型的推理速度,但ROD-YOLOv5s模型仍保持了较高的FPS,达到58帧/秒,满足了实时检测任务的需求｡  

本项目模型在远距离目标检测､复杂背景和运动模糊等复杂场景下均表现出较强的鲁棒性,这表明它能够在多变的实际路况中稳定工作,为道路安全提供了有力的技术支持｡尽管ROD-YOLOv5s模型在本次研究中表现出色,但认识到仍有进一步优化和改进的空间｡未来的工作将集中在探索更高效的网络结构和注意力机制,以进一步提升模型的性能和鲁棒性｡还将研究更先进的训练策略,如知识蒸馏和迁移学习,以提高模型在有限数据下的学习能力｡此外,将模型应用于更多实际场景,如无人驾驶车辆和智能交通系统,以验证其广泛的适用性,也是未来工作的重点｡期待通过这些努力,能够进一步推动该模型的发展,以满足更广泛的实际需求｡  


## 参考文献  
[1] CNNIC发布第49次《中国互联网络发展状况统计报告》[J].新闻潮,2022,(02):3.  
[2] 林德铝,刘畅,陈琦,等.基于低秩分解的YOLO轻量化目标检测模型[J].机车电传动,2024,(01):138-144.DOI:10.13890/j.issn.1000-128X.2024.01.120.  
[3] 刘茴香.微量DNA提取站关键工件智能识别与检测技术研究[D].长春工业大学,2022.DOI:10.27805/d.cnki.gccgy.2022.000070.  
[4] 王国庆,李璇,杨理践,等.基于改进YOLOv5算法的管道漏磁信号识别方法[J].计算机测量与控制,2022,30(08):147-154.DOI:10.16526/j.cnki.11-4762/tp.2022.08.024.  
[5] 蒋云超.基于双模调制的细粒度图像识别[D].电子科技大学,2021.DOI:10.27005/d.cnki.gdzku.2021.001085.  
[6] 朱智惟,单建华,余贤海,等.基于YOLOv5s的番茄采摘机器人目标检测技术[J].传感器与微系统,2023,42(06):129-132.DOI:10.13873/J.1000-9787(2023)06-0129-04.  
[7] 杨健.基于视觉的水下目标识别与定位技术研究[D].桂林电子科技大学,2022.DOI:10.27049/d.cnki.ggldc.2022.000169.  
[8] 马新舒.面向无人驾驶车的交通标志检测技术研究[D].桂林电子科技大学,2021.DOI:10.27049/d.cnki.ggldc.2021.000294.  
[9] 武建鹏.基于目标检测的模型压缩算法研究[D].天津大学,2022.DOI:10.27356/d.cnki.gtjdu.2022.000545.  
[10] 刘麒,盛德庆,孙万龙,等.基于改进YOLOv5s的水果目标检测研究[J].吉林化工学院学报,2023,40(07):34-41.DOI:10.16039/j.cnki.cn22-1249.2023.07.007.  </code></pre>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CIoU-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" rel="tag">CIoU 损失函数</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PAN%E9%87%91%E5%AD%97%E5%A1%94%E6%B3%A8%E6%84%8F%E5%8A%9B/" rel="tag">PAN金字塔注意力</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SE%E6%A8%A1%E5%9D%97/" rel="tag">SE模块</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/YOLO/" rel="tag">YOLO</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
  </article>
  

  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2015-2025
        <i class="ri-heart-fill heart_icon"></i> Xinyu Zhuang
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="很荣幸被您认识"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" target="_blank" rel="noopener" href="http://shenyu-vip.lofter.com">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2019/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->
 
    
        <link rel="stylesheet" href="https://cdn.staticfile.org/KaTeX/0.15.1/katex.min.css">
        <script src="https://cdn.staticfile.org/KaTeX/0.15.1/katex.min.js"></script>
        <script src="https://cdn.staticfile.org/KaTeX/0.15.1/contrib/auto-render.min.js"></script>
        
    
 
<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>